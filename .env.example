# Example environment variables for Cognio
# Copy this to .env and customize as needed

# Database
DB_PATH=./data/memory.db

# Embeddings
# Recommended models (from fastest/lightest to most accurate):
# - all-MiniLM-L6-v2 (384-dim, ~80MB, FAST - good for small/medium datasets)
# - paraphrase-MiniLM-L6-v2 (384-dim, ~80MB, better paraphrase detection)
# - paraphrase-multilingual-MiniLM-L12-v2 (384-dim, ~470MB, balanced multilingual)
# - paraphrase-multilingual-mpnet-base-v2 (768-dim, ~1.1GB, BEST quality but slower)
EMBED_MODEL=all-MiniLM-L6-v2
EMBED_DEVICE=cpu
EMBEDDING_CACHE_PATH=./data/embedding_cache.pkl

# API Server
API_HOST=0.0.0.0
API_PORT=8080
# API_KEY=your-secret-key-here  # Uncomment to enable API key authentication

# Search
DEFAULT_SEARCH_LIMIT=5
SIMILARITY_THRESHOLD=0.4

# Performance
MAX_TEXT_LENGTH=10000
BATCH_SIZE=32
SUMMARIZE_THRESHOLD=50

# Logging
LOG_LEVEL=info

# Auto-tagging with LLM
AUTOTAG_ENABLED=true
LLM_PROVIDER=groq

# Groq Settings (RECOMMENDED - Free tier: 14,400 requests/day)
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your-groq-api-key-here
# Recommended models (from cheapest to most powerful):
# - llama-3.1-8b-instant ($0.05/$0.08 per 1M tokens - FASTEST, cheapest)
# - gemma2-9b-it ($0.2/$0.2 per 1M tokens - balanced)
# - llama-4-scout-17b-16e-instruct ($0.11/$0.34 per 1M tokens - vision support)
# - openai/gpt-oss-20b ($0.1/$0.5 per 1M tokens - reasoning, prompt caching 50%)
# - openai/gpt-oss-120b ($0.15/$0.75 per 1M tokens - BEST quality, reasoning, caching 50%)
GROQ_MODEL=openai/gpt-oss-120b

# OpenAI Settings (alternative - more expensive but widely available)
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_MODEL=gpt-4o-mini

# Summarization
SUMMARIZATION_ENABLED=true
# Methods: extractive (clustering-based, no API calls) or abstractive (LLM-based, uses API)
SUMMARIZATION_METHOD=abstractive

